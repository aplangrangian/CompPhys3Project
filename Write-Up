\documentclass{homework}

\title{Quantum Mechanics II Computational Project}
\author{Alexander Lange, Sara Ratliff, Roman Kosarzycki}

\begin{document}

\maketitle

\exercise

To perform Gauss-Jordan elimination with pivoting, we will consider an inhomogeneous system of $N$ linear equations, which can be represented in the following matrix form:

\begin{equation}
\label{1}
\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1N} \\ a_{21} & a_{22} & \cdots & a_{2N} \\ \vdots & \vdots & \ddots & \vdots \\ a_{N1} & a_{N2} & \cdots & a_{NN}
\end{pmatrix}
\begin{pmatrix}
x_1 \\ x_2 \\ \vdots \\ x_N
\end{pmatrix} = 
\begin{pmatrix}
b_1 \\ b_2 \\ \vdots \\ b_N
\end{pmatrix}
\end{equation}

The Gauss-Jordan algorithm transforms the $N \times N$ matrix $\mathbf{A}$ into a triangular matrix:

\begin{equation}
\label{2}
\begin{pmatrix}
a'_{11} & a'_{12} & \cdots & a'_{1N} \\ 0 & a'_{22} & \cdots & a'_{2N} \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & a'_{NN}
\end{pmatrix}
\begin{pmatrix}
x_1 \\ x_2 \\ \vdots \\ x_N
\end{pmatrix} = 
\begin{pmatrix}
b'_1 \\ b'_2 \\ \vdots \\ b'_N
\end{pmatrix}
\end{equation}

First, we created the augment matrix $\mathbf{\tilde{A}}$ by appending the vector $\mathbf{b}$ to form a $N \times (N+1)$ matrix:

\begin{equation}
\label{3}
\mathbf{\tilde{A}} =
\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1N} & b_1 \\ a_{21} & a_{22} & \cdots & a_{2N} & b_2 \\ \vdots & \vdots & \ddots & \vdots  & \vdots \\ a_{N1} & a_{N2} & \cdots & a_{NN} & b_N
\end{pmatrix}
\end{equation}

Given this augment matrix, we then go row by row, first pivoting and then transforming each variable $a_{ji}$. Pivoting is the process of finding the largest value in the first column $a_{j1}$ (including the last column) and moving that whole row to the $j^{th}$ row. Then each of individual components are transformed according to the following:

\begin{equation}
\label{4}
a_{ij} \to a'_{ij} = a_{ij} - \frac{a_{ik}}{a'_{kk}} a'_{kj} \ ; \ k=1,2, \cdots , N \ ; \ i = k+1 , k+2 , \cdots , N \ ; \ j = 1,2, \cdots , N+1
\end{equation}

This process was accomplished in our code in the following manner for an $N \times N$ array $A$:

\begin{lstlisting}[language=Python]

#Define functions first

def pivot(A,k):
	Define Amax to be first diagonal term A[k,k]
	if  any other element in same col > Amax, for all elements in col
		Amax = larger element
		
def GaussianEliminationWPivot(A):
	#Elimination
	for i in range(N):
	    Recall function pivot(A,i)
	    Elimination for each element in each column
			Eq. 43 from writeup
	x=Nx1 empty matrix
	#Backward Substitution method
	for i in range(N):
		sum=0
		for j in range(N):
			EQ. 37 from write-up. Sum value is changed in this procedure.
	#Returns solutions to matrix equation
	return x

def random(i,N,valmin,valmax):
    Define N number of 2 random matrices for testing.
    A = random generated number of a NxN between min value and max value
    B = random generated number of a 1xN between min value and max value
    return A,B


def ToList(A,B):
    Convert A to list (dtype required)
    Convert B to list
    Append B to A as new col
        
    return A

#Check by matrix multiplication
A,B = random(1,10,0,10) 
A_List=ToList(A,B)   
sols = GaussianEliminationWPivot(A_List)
check = abs(np.matmul(A,sols) - B)< Some Margin of Error (1e-14 ~50%)
print(np.matmul(A,sols))
print(check)	

\end{lstlisting}

\pagebreak

\exercise

In order to perform the Gaussian integration, we used the following relation:

\begin{equation}
\label{a}
\int^{\infty}_0 dq \ f(q) = \sum^N_{i=1} \tilde{\omega}_if_i + R_N[f,q] \ , \ f_i=f(q_i) \ , \ \tilde{\omega}_i = \omega_i \left[ \frac{dq}{dx} \right]_{x=x_i}
\end{equation}

The term $R_N$ represents the remainder, but we will choose a sufficiently large $N$ such that the remainder is negligible. The weight functions are defined using Gauss-Legendre quadrature.  For our purposes, we will use the following definition of $q$:

\begin{equation}
\label{b}
q(x)= q_0 \frac{1+x}{1-x}
\end{equation}

Eq.~(\ref{b}) allows $q$ to vary from 0 to $\infty$ when $x$ varies from -1 to 1. Our code completes this process in the following manner:

\begin{lstlisting}[language=Python]

#Define functions

def func(q):
	Define the function being integrated
	return function(q)
	
def q(x):
	return q(x) from eq. (6)

def weight_func(Mesh_size):
	return mesh asbsesca and weight for a given mesh size
	
def GaussInteg(X,N,K):
	Takes in asbseca, mesh size, and mesh weights
	for j in range (N):
		Sum in eq. (22) from write-up
	return sum
	
#Set mesh size

N=mesh size

#Body of code

asbsesca = weight_func(N)[0]
weights = weight_func(N)[1]
Integral=GaussInteg(asbsesca,N,weights)

\end{lstlisting}

\pagebreak

\exercise

Next, the potential matrix elements $U(p,q)$ were generated for a given mesh. 

\pagebreak

\exercise

In order to implement the Gauss-Jordan elimination in part 1, an augmented matrix needs to be generated. 

\pagebreak

\exercise

Finally, the system of linear equations from part 4 was solved and the Jost function was calculated. 

\end{document}
